{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========================================================================\n",
    "# Hello. In this notebook, I will be providing Map Reduce \n",
    "# examples in Python, which will work as Hadoop Streaming jobs.\n",
    "# @author: Souradeep Sinha\n",
    "#=========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#==========================================================================\n",
    "# This example is from Tanmay Deshpande's list of sample Map \n",
    "# Reduce problems which are originally written in Java\n",
    "# at http://hadooptutorials.co.in/tutorials/mapreduce/advanced-map-reduce-examples-1.html#\n",
    "# \n",
    "# Problem Statement:\n",
    "# XYZ.com is an online music website where users listen to \n",
    "# various tracks, the data gets collected like shown below. \n",
    "# Write a map reduce program to get following stats:\n",
    "# \n",
    "# Number of unique listeners\n",
    "# Number of times the track was shared with others\n",
    "# Number of times the track was listened to on the radio\n",
    "# Number of times the track was listened to in total\n",
    "# Number of times the track was skipped on the radio\n",
    "# The data is coming in log files and looks like as shown below.\n",
    "# \n",
    "# UserId|TrackId|Shared|Radio|Skip\n",
    "# 111115|222|0|1|0\n",
    "# 111113|225|1|0|0\n",
    "# 111117|223|0|1|1\n",
    "# 111115|225|1|0|0\n",
    "#=========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 1, Mapper Function. File saved as mapper.py\n",
    "\n",
    "from sys import stdin\n",
    "\n",
    "def mapper():\n",
    "    for line in stdin:\n",
    "        data = line.split(\"|\")\n",
    "        if len(data) == 5:\n",
    "            uid, tid = data[:2]\n",
    "            print \"{0}\\t{1}\".format(tid, uid)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 1, Reduce Function. File saved as reducer.py\n",
    "\n",
    "from sys import stdin\n",
    "\n",
    "def reducer():\n",
    "    oldKey = None\n",
    "    aggregator = list()\n",
    "    for line in stdin:\n",
    "        data = line.split(\"\\t\")\n",
    "        if not(len(data) == 2):\n",
    "            continue\n",
    "        thisKey, thisValue = data\n",
    "        if oldKey and not(oldKey == thisKey):\n",
    "            print \"{0}\\t{1}\".format(oldKey, str(len(list(set(aggregator)))))\n",
    "            aggregator = list()\n",
    "            oldKey = thisKey\n",
    "        oldKey = thisKey\n",
    "        aggregator.append(thisValue)\n",
    "    print \"{0}\\t{1}\".format(oldKey, str(len(list(set(aggregator)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The mapper ad the reducer can be passed to the Hadoop \n",
    "# framework along with the data file, output folder (in  \n",
    "# HDFS) and the mapper-reducer file combinations. Please\n",
    "# ensure that the output folder does not already exist.\n",
    "\n",
    "# For a sanity check, the mapper and reducer can be checked\n",
    "# on the local machine terminal, using the first 1000 lines\n",
    "# of the log file (log.dat) and piping the results into \n",
    "# mapper and reducer functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $> cat -1000 log.dat | python mapper.py \\\n",
    "# $> | sort | python reducer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
